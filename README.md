```markdown
# ğŸ” A Mobile App for Visually Impaired

A Flutter + Flask powered assistive AI app that transforms images into audio-based insights using object detection, OCR, and image captioning.

---

## ğŸ“± Overview

This mobile application is designed to empower **visually impaired users** by transforming captured or uploaded images into meaningful **spoken feedback**. Using artificial intelligence, the app provides three core functionalities:

- ğŸ¯ **Object Detection**
- ğŸ–¼ï¸ **Image Captioning**
- ğŸ“ **Text Recognition (OCR)**

All features are accessible through a **simple interface**, built in Flutter, and backed by a Flask API that runs AI models.

---

## ğŸ§  Core Features

| Feature              | Description                                                                 |
|----------------------|-----------------------------------------------------------------------------|
| ğŸ” **Object Detection** | Identifies multiple objects within the image using **SSD MobileNet**.        |
| ğŸ–‹ï¸ **Image Captioning** | Describes the image using a full sentence via the **BLIP model**.           |
| ğŸ”¤ **Text Recognition** | Extracts text content from the image using **Tesseract OCR**.              |
| ğŸ”Š **Audio Feedback**    | All results are read aloud using **Text-to-Speech** for user convenience. |

---

## ğŸ“‚ Project Structure

```

A-Mobile-App-for-Visually-Impaired/
â”œâ”€â”€ VisualAI\_backend/               # Flask backend (AI logic)
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ static/, .venv/, \*.mp3, etc.
â”‚
â”œâ”€â”€ visually\_impaired\_assist/       # Flutter frontend (mobile app)
â”‚   â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ android/
â”‚   â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ pubspec.yaml
â”‚   â””â”€â”€ build/, .dart\_tool/, etc.
â”‚
â””â”€â”€ README.md

````

---

## ğŸš€ How to Run the Project

### âš™ï¸ 1. Backend Setup (Flask API)

```bash
cd VisualAI_backend
python -m venv venv
venv\Scripts\activate   # On Windows
pip install -r requirements.txt
python app.py
````

ğŸ”— Server runs at: `http://localhost:5000/`

---

### ğŸ“² 2. Flutter App Setup

```bash
cd visually_impaired_assist
flutter pub get
flutter run
```

ğŸ“± Connect a physical Android device or emulator to run the app.

---

## ğŸ”— Backendâ€“Frontend Communication

* The Flutter app sends a captured or uploaded image + selected task (object detection, captioning, OCR) to the Flask server.
* The backend processes the image and returns the result.
* The app reads the result out loud using **TTS (Text-to-Speech)**.

---

## ğŸ§¾ Tech Stack

| Layer             | Technologies Used                                               |
| ----------------- | --------------------------------------------------------------- |
| **Frontend**      | Flutter, Dart, image\_picker, flutter\_tts, http                |
| **Backend**       | Flask, Python, Tesseract OCR, SSD MobileNet, BLIP, gTTS/pyttsx3 |
| **Communication** | REST API (HTTP)                                                 |

---

## ğŸ“‚ Recommended `.gitignore`

### For `VisualAI_backend/`

```
*.mp3
.venv/
__pycache__/
*.pyc
```

### For `visually_impaired_assist/`

```
build/
.dart_tool/
.flutter-plugins
.packages
pubspec.lock
```

---

## ğŸ‘©â€ğŸ’» Developer Info

**Project Title**: *A Mobile App for Visually Impaired*
**Academic Year**: *2024â€“2025*
**Technology Focus**: Assistive Tech, Computer Vision, AI/ML
**Frontend**: Flutter
**Backend**: Flask (Python)

---

## ğŸ™Œ Contributions

Have suggestions or want to contribute?
Feel free to fork the repo, open an issue, or submit a pull request! ğŸ’¡

---

<p align="center"><b>Made with â¤ï¸ for accessibility and inclusion.</b></p>
```

---
